{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "id": "gYyWwlc75gFR",
        "outputId": "1faedfe5-eb9f-48a3-e551-6fc156ae0ddd"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz\n",
            "11490434/11490434 [==============================] - 0s 0us/step\n",
            "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/vgg16/vgg16_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
            "58889256/58889256 [==============================] - 0s 0us/step\n",
            "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/resnet/resnet50_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
            "94765736/94765736 [==============================] - 1s 0us/step\n",
            "Epoch 1/10\n",
            " 13/469 [..............................] - ETA: 32:33:40 - loss: 5.5488 - accuracy: 0.0859"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from keras.datasets import mnist\n",
        "from keras.utils import to_categorical\n",
        "from keras.applications import VGG16, ResNet50\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Flatten, Reshape\n",
        "from keras.optimizers import Adam\n",
        "from keras.preprocessing.image import img_to_array, array_to_img\n",
        "from keras.layers import UpSampling2D\n",
        "\n",
        "# Load MNIST dataset\n",
        "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
        "\n",
        "# Normalize pixel values to be between 0 and 1\n",
        "x_train = x_train.astype('float32') / 255\n",
        "x_test = x_test.astype('float32') / 255\n",
        "# Resize images to fit the input size required by VGG16 and ResNet50\n",
        "x_train_resized = np.expand_dims(x_train, axis=-1)\n",
        "x_train_resized = np.repeat(x_train_resized, 3, axis=-1)  # Make it three channels for VGG16 and ResNet50\n",
        "x_test_resized = np.expand_dims(x_test, axis=-1)\n",
        "x_test_resized = np.repeat(x_test_resized, 3, axis=-1)\n",
        "\n",
        "# Convert labels to one-hot encoding\n",
        "y_train = to_categorical(y_train, 10)\n",
        "y_test = to_categorical(y_test, 10)\n",
        "\n",
        "# Define base models\n",
        "base_model_vgg16 = VGG16(weights='imagenet', include_top=False, input_shape=(224, 224, 3))\n",
        "base_model_resnet50 = ResNet50(weights='imagenet', include_top=False, input_shape=(224, 224, 3))\n",
        "\n",
        "# Create model architecture\n",
        "model_vgg16 = Sequential([\n",
        "    UpSampling2D(size=(8, 8)),\n",
        "    base_model_vgg16,\n",
        "    Flatten(),\n",
        "    Dense(256, activation='relu'),\n",
        "    Dense(10, activation='softmax')\n",
        "])\n",
        "\n",
        "model_resnet50 = Sequential([\n",
        "    UpSampling2D(size=(8, 8)),\n",
        "    base_model_resnet50,\n",
        "    Flatten(),\n",
        "    Dense(256, activation='relu'),\n",
        "    Dense(10, activation='softmax')\n",
        "])\n",
        "\n",
        "# Compile models\n",
        "model_vgg16.compile(optimizer=Adam(), loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "model_resnet50.compile(optimizer=Adam(), loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# Train models\n",
        "history_vgg16 = model_vgg16.fit(x_train_resized, y_train, epochs=10, batch_size=128, validation_data=(x_test_resized, y_test))\n",
        "history_resnet50 = model_resnet50.fit(x_train_resized, y_train, epochs=10, batch_size=128, validation_data=(x_test_resized, y_test))\n",
        "\n",
        "# Plot accuracy and loss curves\n",
        "plt.figure(figsize=(12, 6))\n",
        "plt.subplot(1, 2, 1)\n",
        "plt.plot(history_vgg16.history['accuracy'], label='VGG16 Training Accuracy')\n",
        "plt.plot(history_vgg16.history['val_accuracy'], label='VGG16 Validation Accuracy')\n",
        "plt.plot(history_resnet50.history['accuracy'], label='ResNet50 Training Accuracy')\n",
        "plt.plot(history_resnet50.history['val_accuracy'], label='ResNet50 Validation Accuracy')\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.legend()\n",
        "plt.title('Training and Validation Accuracy')\n",
        "\n",
        "plt.subplot(1, 2, 2)\n",
        "plt.plot(history_vgg16.history['loss'], label='VGG16 Training Loss')\n",
        "plt.plot(history_vgg16.history['val_loss'], label='VGG16 Validation Loss')\n",
        "plt.plot(history_resnet50.history['loss'], label='ResNet50 Training Loss')\n",
        "plt.plot(history_resnet50.history['val_loss'], label='ResNet50 Validation Loss')\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Loss')\n",
        "plt.legend()\n",
        "plt.title('Training and Validation Loss')\n",
        "\n",
        "plt.show()\n",
        "\n",
        "# Report validation accuracy\n",
        "print(\"VGG16 Validation Accuracy:\", history_vgg16.history['val_accuracy'][-1])\n",
        "print(\"ResNet50 Validation Accuracy:\", history_resnet50.history['val_accuracy'][-1])"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}